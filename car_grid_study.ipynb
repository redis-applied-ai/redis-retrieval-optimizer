{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b64475",
   "metadata": {},
   "source": [
    "# Car Grid study\n",
    "\n",
    "The example will show you how to define custom functions and search methods for the retrieval optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b66894d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "import json\n",
    "\n",
    "with open('data/car_corpus.json', 'r') as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "with open('data/car_queries.json', 'r') as f:\n",
    "    queries = json.load(f)\n",
    "\n",
    "with open('data/car_qrels.json', 'r') as f:\n",
    "    qrels = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ca1a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Mazda3_8Y64-EA-08A_Edition1 Page1 Tuesday, November 27 2007 9:0 AM\\n\\nForm No.8Y64-EA-08A\\n\\nBlack plate (1,1)\\n\\nMazda3_8Y64-EA-08A_Edition1 Page2 Tuesday, November 27 2007 9:0 AM\\n\\nForm No.8Y64-EA-08A\\n\\nBlack plate (2,1)\\n\\nMazda3_8Y64-EA-08A_Edition1 Page3 Tuesday, November 27 2007 9:0 AM\\n\\nBlack plate (3,1)\\n\\nA Word to Mazda Owners\\n\\nThank you for choosing a Mazda. We at Mazda design and build vehicles with complete customer satisfaction in mind.\\n\\nTo help ensure enjoyable and trouble-free operation of your Mazda, read this manual carefully and follow its recommendations.\\n\\nAn Authorized Mazda Dealer knows your vehicle best. So when maintenance or service is necessary, that's the place to go.\\n\\nOur nationwide network of Mazda professionals is dedicated to providing you with the best possible service.\\n\\nWe assure you that all of us at Mazda have an ongoing interest in your motoring pleasure and in your full satisfaction with your Mazda product.\\n\\nMazda Motor Corporation HIROSHIMA, JAPAN\\n\\nImportant Notes About This Manual Keep this manual in the glove box as a handy reference for the safe and enjoyable use of your Mazda. Should you resell the vehicle, leave this manual with it for the next owner.\\n\\nAll specifications and descriptions are accurate at the time of printing. Because improvement is a constant goal at Mazda, we reserve the right to make changes in specifications at any time without notice and without obligation.\\n\\nEvent Data Recorder This vehicle is equipped with an event data recorder. In the event of a crash, this device records data related to vehicle dynamics and safety systems for a short period of time. These data can help provide a better understanding of the circumstances in which crashes and injuries occur and lead to the designing of safer vehicles.\\n\\nAir Conditioning and the Environment Your Mazda's genuine air conditioner is filled with HFC134a (R134a), a refrigerant that has been found not to damage the earth's ozone layer. If the air conditioner does not operate properly, consult an Authorized Mazda Dealer.\\n\\nPerchlorate Certain components of this vehicle such as [air bag modules, seat belt pretensioners, lithium batteries, ...] may contain Perchlorate Materialâ€“ Special handling may apply for service or vehicle end of life disposal. See www.dtsc.ca.gov/hazardouswaste/perchlorate.\\n\\nPlease be aware that this manual applies to all models, equipment and options. As a result, you may find some explanations for equipment not installed on your vehicle.\",\n",
       " 'query_metadata': {'make': 'mazda', 'model': '3'},\n",
       " 'item_id': 'mazda_3:0'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data is in a different format than the last example\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cddb9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'At what speed should I shift from 2 to 3 with a manual transmission?',\n",
       " 'query_metadata': {'make': 'mazda', 'model': '3'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[\"car-1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c34a67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car-1': {'mazda_3:86': 1},\n",
       " 'car-2': {'mazda_3:92': 1, 'mazda_3:93': 1},\n",
       " 'car-3': {'mazda_3:84': 1, 'mazda_3:75': 1, 'mazda_3:105': 1},\n",
       " 'car-4': {'mazda_3:188': 1},\n",
       " 'car-5': {'mazda_3:68': 1, 'mazda_3:69': 1},\n",
       " 'car-6': {'mazda_3:105': 1, 'mazda_3:83': 1},\n",
       " 'car-7': {'mazda_3:195': 1, 'mazda_3:194': 1},\n",
       " 'car-8': {'mazda_3:226': 1,\n",
       "  'mazda_3:227': 1,\n",
       "  'mazda_3:229': 1,\n",
       "  'mazda_3:76': 1},\n",
       " 'car-9': {'mazda_3:176': 1, 'mazda_3:175': 1},\n",
       " 'car-10': {'mazda_3:179': 1,\n",
       "  'mazda_3:209': 1,\n",
       "  'mazda_3:211': 1,\n",
       "  'mazda_3:212': 1,\n",
       "  'mazda_3:213': 1,\n",
       "  'mazda_3:210': 1}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# must be this format\n",
    "qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ce092",
   "metadata": {},
   "source": [
    "# Define a study config\n",
    "\n",
    "To set the parameters of our study we need to define a study configuration file.\n",
    "\n",
    "Example:\n",
    "```yaml\n",
    "# paths to necessary data files\n",
    "corpus: \"data/car_corpus.json\" # optional if from_existing\n",
    "queries: \"data/car_queries.json\"\n",
    "qrels: \"data/car_qrels.json\"\n",
    "\n",
    "# vector field names\n",
    "index_settings:\n",
    "  name: \"car\"\n",
    "  prefix: \"car\" # prefix for index name\n",
    "  vector_field_name: \"vector\" # name of the vector field to search on\n",
    "  text_field_name: \"text\" # name of the text field for lexical search\n",
    "  id_field_name: \"_id\"\n",
    "  from_existing: false\n",
    "  additional_fields:\n",
    "    - name: \"make\" # fields to match our situation\n",
    "      type: \"tag\"\n",
    "    - name: \"model\"\n",
    "      type: \"tag\"\n",
    "  vector_dim: 384 # should match first embedding model or from_existing\n",
    "\n",
    "# will run all search methods for each embedding model and then iterate\n",
    "embedding_models: # embedding cache would be awesome here.\n",
    "# if from_existing is true, first record is assumed to be the one used to create the index\n",
    "  - type: \"hf\"\n",
    "    model: \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    dim: 384\n",
    "    embedding_cache_name: \"vec-cache\" # avoid names with including 'ret-opt' as this can cause collisions\n",
    "\n",
    "search_methods: [\"basic_vector\", \"pre_filter_vector\"] # must match what is passed as search_method_map\n",
    "```\n",
    "\n",
    "## Custom search methods\n",
    "\n",
    "The data for this study has fields `make` and `model` which would be good to apply as a pre-filter. However, none of the default search methods account for a specific query with these particular fields but we can easily define our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6dade2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:20:00 sentence_transformers.cross_encoder.CrossEncoder INFO   Use pytorch device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from redisvl.query import VectorQuery\n",
    "from redisvl.query.filter import Tag\n",
    "\n",
    "from redis_retrieval_optimizer.search_methods.vector import make_score_dict_vec\n",
    "\n",
    "def vector_query(query_info, num_results: int, emb_model) -> VectorQuery:\n",
    "    vector = emb_model.embed(query_info[\"query\"], as_buffer=True)\n",
    "\n",
    "    return VectorQuery(\n",
    "        vector=vector,\n",
    "        vector_field_name=\"vector\",\n",
    "        num_results=num_results,\n",
    "        return_fields=[\"_id\", \"make\", \"model\", \"text\"],  # update to read from env maybe?\n",
    "    )\n",
    "\n",
    "def pre_filter_query(query_info, num_results, emb_model) -> VectorQuery:\n",
    "    vec = emb_model.embed(query_info[\"query\"])\n",
    "    make = query_info[\"query_metadata\"][\"make\"]\n",
    "    model = query_info[\"query_metadata\"][\"model\"]\n",
    "\n",
    "    filter = (Tag(\"make\") == make) & (Tag(\"model\") == model)\n",
    "\n",
    "    # Create a vector query\n",
    "    query = VectorQuery(\n",
    "        vector=vec,\n",
    "        vector_field_name=\"vector\",\n",
    "        num_results=num_results,\n",
    "        filter_expression=filter,\n",
    "        return_fields=[\"_id\", \"make\", \"model\", \"text\"]\n",
    "    )\n",
    "\n",
    "    return query\n",
    "\n",
    "def gather_pre_filter_results(queries, index, emb_model):\n",
    "    redis_res_vector = {}\n",
    "\n",
    "    for key in queries:\n",
    "        query_info = queries[key]\n",
    "        vec_query = pre_filter_query(query_info, 10, emb_model)\n",
    "        try:\n",
    "            res = index.query(vec_query)\n",
    "            score_dict = make_score_dict_vec(res)\n",
    "        except Exception as e:\n",
    "            print(f\"failed for {key}, {text_query}\")\n",
    "            score_dict = {}\n",
    "\n",
    "        redis_res_vector[key] = score_dict\n",
    "    return redis_res_vector\n",
    "\n",
    "\n",
    "def gather_vector_results(queries, index, emb_model):\n",
    "    redis_res_vector = {}\n",
    "\n",
    "    for key in queries:\n",
    "        text_query = queries[key]\n",
    "        vec_query = vector_query(text_query, 10, emb_model)\n",
    "        # try:\n",
    "        res = index.query(vec_query)\n",
    "        score_dict = make_score_dict_vec(res)\n",
    "        # except Exception as e:\n",
    "        #     print(f\"failed for {key}, {text_query}\")\n",
    "        #     score_dict = {}\n",
    "        redis_res_vector[key] = score_dict\n",
    "    return redis_res_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8339f",
   "metadata": {},
   "source": [
    "# Custom corpus processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfce2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_car_corpus(\n",
    "    corpus, emb_model\n",
    "):\n",
    "    corpus_data = []\n",
    "    corpus_texts = [c[\"text\"] for c in corpus]\n",
    "\n",
    "    text_embeddings = emb_model.embed_many(corpus_texts, as_buffer=True)\n",
    "\n",
    "    for i, c in enumerate(corpus):\n",
    "        corpus_data.append(\n",
    "            {\n",
    "                \"_id\": c[\"item_id\"],\n",
    "                \"text\": c[\"text\"],\n",
    "                \"make\": c[\"query_metadata\"][\"make\"],\n",
    "                \"model\": c[\"query_metadata\"][\"model\"],\n",
    "                \"vector\": text_embeddings[i],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return corpus_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e316b4",
   "metadata": {},
   "source": [
    "# Run a study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc56171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:20:34 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:20:34 sentence_transformers.SentenceTransformer INFO   Use pytorch device_name: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142fd6ec687343b0b1fda6cce47fae38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreating: loading corpus from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:20:49 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "15:20:49 sentence_transformers.SentenceTransformer INFO   Use pytorch device_name: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b625fc78f9484c922590fee0ce9b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running search method: basic_vector\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bbd1af9f064517a48505e831cffc75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7288b5bafd4a6f8c8158cca7eec2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be162e233424aefbea60f9a31a82f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ef0f6624e047c7981d2d47ac09557d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3999dcaedb57486e9cc3d41f5e908b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784c106dbe604cd985962243f22276e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd16d7307b234cea99f4e9132afeb1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f81a7d9fafd484897c256f4875192e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bd5f8e3fea41878b88070352dc60c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running search method: pre_filter_vector\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from redis_retrieval_optimizer.grid_study import run_grid_study\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "CUSTOM_SEARCH_METHOD_MAP = {\n",
    "    \"basic_vector\": gather_vector_results,\n",
    "    \"pre_filter_vector\": gather_pre_filter_results,\n",
    "}\n",
    "\n",
    "# load environment variables containing necessary credentials\n",
    "load_dotenv()\n",
    "\n",
    "redis_url = os.environ.get(\"REDIS_URL\", \"redis://localhost:6379/0\")\n",
    "\n",
    "metrics = run_grid_study(\n",
    "    config_path=\"custom_grid_study_config.yaml\",\n",
    "    redis_url=\"redis://localhost:6379/0\",\n",
    "    corpus_processor=process_car_corpus,\n",
    "    search_method_map=CUSTOM_SEARCH_METHOD_MAP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ef7edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search_method': ['basic_vector', 'pre_filter_vector'],\n",
       " 'ret_k': [6, 6],\n",
       " 'algorithm': ['flat', 'flat'],\n",
       " 'ef_construction': [0, 0],\n",
       " 'ef_runtime': [0, 0],\n",
       " 'm': [0, 0],\n",
       " 'distance_metric': ['cosine', 'cosine'],\n",
       " 'vector_data_type': ['float32', 'float32'],\n",
       " 'model': ['sentence-transformers/all-MiniLM-L6-v2',\n",
       "  'sentence-transformers/all-MiniLM-L6-v2'],\n",
       " 'model_dim': [384, 384],\n",
       " 'recall@k': [0.775, 0.9333333333333333],\n",
       " 'ndcg@k': [0.6519546808446834, 0.8822834961862057],\n",
       " 'f1@k': [0.4628787878787879, 0.5786075036075037],\n",
       " 'total_indexing_time': [0, 0],\n",
       " 'precision': [0.36, 0.4600000000000001]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834e6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
