# paths to necessary data files
corpus: "data/nfcorpus_corpus.json" # optional if from_existing
queries: "data/nfcorpus_queries.json"
qrels: "data/nfcorpus_qrels.json"

# vector field names
vector_field_name: "vector" # name of the vector field to search on
text_field_name: "text" # name of the text field for lexical search
index_settings:
  name: "optimize"
  from_existing: true

# will run all search methods for each embedding model and then iterate
embedding_models: # embedding cache would be awesome here.
# if from_existing is true, first record is assumed to be the one used to create the index
  - type: "hf"
    model: "sentence-transformers/all-MiniLM-L6-v2"
    dim: 384
    embedding_cache_name: "vec-cache" # avoid names with including 'ret-opt' as this can cause collisions
    embedding_cache_redis_url: "redis://localhost:6379"
  # - type: "hf"
  #   model: "intfloat/e5-large-v2"
  #   dim: 1024
  #   embedding_cache_name: "ret-opt-vec-cache"
  #   embedding_cache_redis_url: "redis://localhost:6379"
  # - type: "openai"
  #   model: "text-embedding-3-small"
  #   dim: 1536
  #   embedding_cache_name: "ret-opt-vec-cache"
  #   embedding_cache_redis_url: "redis://localhost:6379"
search_methods: ["bm25", "vector"]