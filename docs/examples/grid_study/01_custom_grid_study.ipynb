{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b64475",
   "metadata": {},
   "source": [
    "# Custom grid study\n",
    "## Why custom functions matter\n",
    "Search and retrieval systems are not one-size-fits-all. While the Retrieval Optimizer provides robust default search methods, real-world data often has unique characteristics that can be leveraged for better results:\n",
    "\n",
    "- Domain-specific metadata may provide critical filtering context (as with the car make/model in this example)\n",
    "- Custom query structures might contain more than just text (like user preferences or specifications)\n",
    "- Performance optimizations can be achieved by pre-filtering before vector search\n",
    "\n",
    "This notebook demonstrates how to create custom search methods and corpus processors that take advantage of your data's unique structure. By defining your own functions, you can:\n",
    "\n",
    "1. Improve relevance by incorporating domain-specific knowledge\n",
    "2. Reduce latency through strategic pre-filtering\n",
    "3. Create apples-to-apples comparisons between baseline and enhanced methods\n",
    "4. Test experimental approaches without modifying the core framework\n",
    "\n",
    "Let's see how to extend the Retrieval Optimizer with custom functions for a simple automotive example.\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8097b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install redis-retrieval-optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270a4f1b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66894d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../resources/cars/car_corpus.json', 'r') as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "with open('../resources/cars/car_queries.json', 'r') as f:\n",
    "    queries = json.load(f)\n",
    "\n",
    "with open('../resources/cars/car_qrels.json', 'r') as f:\n",
    "    qrels = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233fce1c",
   "metadata": {},
   "source": [
    "# View example of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ca1a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Mazda3_8Y64-EA-08A_Edition1 Page1 Tuesday, November 27 2007 9:0 AM\\n\\nForm No.8Y64-EA-08A\\n\\nBlack plate (1,1)\\n\\nMazda3_8Y64-EA-08A_Edition1 Page2 Tuesday, November 27 2007 9:0 AM\\n\\nForm No.8Y64-EA-08A\\n\\nBlack plate (2,1)\\n\\nMazda3_8Y64-EA-08A_Edition1 Page3 Tuesday, November 27 2007 9:0 AM\\n\\nBlack plate (3,1)\\n\\nA Word to Mazda Owners\\n\\nThank you for choosing a Mazda. We at Mazda design and build vehicles with complete customer satisfaction in mind.\\n\\nTo help ensure enjoyable and trouble-free operation of your Mazda, read this manual carefully and follow its recommendations.\\n\\nAn Authorized Mazda Dealer knows your vehicle best. So when maintenance or service is necessary, that's the place to go.\\n\\nOur nationwide network of Mazda professionals is dedicated to providing you with the best possible service.\\n\\nWe assure you that all of us at Mazda have an ongoing interest in your motoring pleasure and in your full satisfaction with your Mazda product.\\n\\nMazda Motor Corporation HIROSHIMA, JAPAN\\n\\nImportant Notes About This Manual Keep this manual in the glove box as a handy reference for the safe and enjoyable use of your Mazda. Should you resell the vehicle, leave this manual with it for the next owner.\\n\\nAll specifications and descriptions are accurate at the time of printing. Because improvement is a constant goal at Mazda, we reserve the right to make changes in specifications at any time without notice and without obligation.\\n\\nEvent Data Recorder This vehicle is equipped with an event data recorder. In the event of a crash, this device records data related to vehicle dynamics and safety systems for a short period of time. These data can help provide a better understanding of the circumstances in which crashes and injuries occur and lead to the designing of safer vehicles.\\n\\nAir Conditioning and the Environment Your Mazda's genuine air conditioner is filled with HFC134a (R134a), a refrigerant that has been found not to damage the earth's ozone layer. If the air conditioner does not operate properly, consult an Authorized Mazda Dealer.\\n\\nPerchlorate Certain components of this vehicle such as [air bag modules, seat belt pretensioners, lithium batteries, ...] may contain Perchlorate Materialâ€“ Special handling may apply for service or vehicle end of life disposal. See www.dtsc.ca.gov/hazardouswaste/perchlorate.\\n\\nPlease be aware that this manual applies to all models, equipment and options. As a result, you may find some explanations for equipment not installed on your vehicle.\",\n",
       " 'query_metadata': {'make': 'mazda', 'model': '3'},\n",
       " 'item_id': 'mazda_3:0'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data is in a different format than the last example\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cddb9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'At what speed should I shift from 2 to 3 with a manual transmission?',\n",
       " 'query_metadata': {'make': 'mazda', 'model': '3'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[\"car-1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c34a67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car-1': {'mazda_3:86': 1},\n",
       " 'car-2': {'mazda_3:92': 1, 'mazda_3:93': 1},\n",
       " 'car-3': {'mazda_3:84': 1, 'mazda_3:75': 1, 'mazda_3:105': 1},\n",
       " 'car-4': {'mazda_3:188': 1},\n",
       " 'car-5': {'mazda_3:68': 1, 'mazda_3:69': 1},\n",
       " 'car-6': {'mazda_3:105': 1, 'mazda_3:83': 1},\n",
       " 'car-7': {'mazda_3:195': 1, 'mazda_3:194': 1},\n",
       " 'car-8': {'mazda_3:226': 1,\n",
       "  'mazda_3:227': 1,\n",
       "  'mazda_3:229': 1,\n",
       "  'mazda_3:76': 1},\n",
       " 'car-9': {'mazda_3:176': 1, 'mazda_3:175': 1},\n",
       " 'car-10': {'mazda_3:179': 1,\n",
       "  'mazda_3:209': 1,\n",
       "  'mazda_3:211': 1,\n",
       "  'mazda_3:212': 1,\n",
       "  'mazda_3:213': 1,\n",
       "  'mazda_3:210': 1}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# must be this format\n",
    "qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ce092",
   "metadata": {},
   "source": [
    "# Define a study config\n",
    "\n",
    "Example:\n",
    "```yaml\n",
    "# paths to necessary data files\n",
    "corpus: \"data/car_corpus.json\" # optional if from_existing\n",
    "queries: \"data/car_queries.json\"\n",
    "qrels: \"data/car_qrels.json\"\n",
    "\n",
    "# vector field names\n",
    "index_settings:\n",
    "  name: \"car\"\n",
    "  prefix: \"car\" # prefix for index name\n",
    "  vector_field_name: \"vector\" # name of the vector field to search on\n",
    "  text_field_name: \"text\" # name of the text field for lexical search\n",
    "  id_field_name: \"_id\"\n",
    "  from_existing: false\n",
    "  additional_fields:\n",
    "    - name: \"make\" # fields to match our situation\n",
    "      type: \"tag\"\n",
    "    - name: \"model\"\n",
    "      type: \"tag\"\n",
    "  vector_dim: 384 # should match first embedding model or from_existing\n",
    "\n",
    "# will run all search methods for each embedding model and then iterate\n",
    "embedding_models: # embedding cache would be awesome here.\n",
    "# if from_existing is true, first record is assumed to be the one used to create the index\n",
    "  - type: \"hf\"\n",
    "    model: \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    dim: 384\n",
    "    embedding_cache_name: \"vec-cache\" # avoid names with including 'ret-opt' as this can cause collisions\n",
    "\n",
    "search_methods: [\"basic_vector\", \"pre_filter_vector\"] # must match what is passed as search_method_map\n",
    "```\n",
    "\n",
    "## Custom search methods\n",
    "\n",
    "The data for this study has fields `make` and `model` which would be good to apply as a pre-filter. However, none of the default search methods account for a specific query with these particular fields but we can easily define our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6dade2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranx import Run\n",
    "from redis_retrieval_optimizer.search_methods.base import run_search_w_time\n",
    "from redisvl.query import VectorQuery\n",
    "from redisvl.query.filter import Tag\n",
    "\n",
    "from redis_retrieval_optimizer.schema import SearchMethodInput, SearchMethodOutput\n",
    "from redis_retrieval_optimizer.search_methods.vector import make_score_dict_vec\n",
    "\n",
    "def vector_query(query_info, num_results: int, emb_model) -> VectorQuery:\n",
    "    vector = emb_model.embed(query_info[\"query\"], as_buffer=True)\n",
    "\n",
    "    return VectorQuery(\n",
    "        vector=vector,\n",
    "        vector_field_name=\"vector\",\n",
    "        num_results=num_results,\n",
    "        return_fields=[\"_id\", \"make\", \"model\", \"text\"],  # update to read from env maybe?\n",
    "    )\n",
    "\n",
    "def pre_filter_query(query_info, num_results, emb_model) -> VectorQuery:\n",
    "    vec = emb_model.embed(query_info[\"query\"])\n",
    "    make = query_info[\"query_metadata\"][\"make\"]\n",
    "    model = query_info[\"query_metadata\"][\"model\"]\n",
    "\n",
    "    filter = (Tag(\"make\") == make) & (Tag(\"model\") == model)\n",
    "\n",
    "    # Create a vector query\n",
    "    query = VectorQuery(\n",
    "        vector=vec,\n",
    "        vector_field_name=\"vector\",\n",
    "        num_results=num_results,\n",
    "        filter_expression=filter,\n",
    "        return_fields=[\"_id\", \"make\", \"model\", \"text\"]\n",
    "    )\n",
    "\n",
    "    return query\n",
    "\n",
    "def gather_pre_filter_results(search_method_input: SearchMethodInput) -> SearchMethodOutput:\n",
    "    redis_res_vector = {}\n",
    "\n",
    "    for key in search_method_input.raw_queries:\n",
    "        query_info = search_method_input.raw_queries[key]\n",
    "        query = pre_filter_query(query_info, 10, search_method_input.emb_model)\n",
    "        res = run_search_w_time(\n",
    "            search_method_input.index, query, search_method_input.query_metrics\n",
    "        )\n",
    "        score_dict = make_score_dict_vec(res, id_field_name=\"_id\")\n",
    "\n",
    "        redis_res_vector[key] = score_dict\n",
    "\n",
    "    return SearchMethodOutput(\n",
    "        run=Run(redis_res_vector),\n",
    "        query_metrics=search_method_input.query_metrics,\n",
    "    )\n",
    "\n",
    "\n",
    "def gather_vector_results(search_method_input: SearchMethodInput) -> SearchMethodOutput:\n",
    "    redis_res_vector = {}\n",
    "\n",
    "    for key in search_method_input.raw_queries:\n",
    "        text_query = search_method_input.raw_queries[key]\n",
    "        vec_query = vector_query(text_query, 10, search_method_input.emb_model)\n",
    "        res = run_search_w_time(\n",
    "            search_method_input.index, vec_query, search_method_input.query_metrics\n",
    "        )\n",
    "        score_dict = make_score_dict_vec(res, id_field_name=\"_id\")\n",
    "        redis_res_vector[key] = score_dict\n",
    "        \n",
    "    return SearchMethodOutput(\n",
    "        run=Run(redis_res_vector),\n",
    "        query_metrics=search_method_input.query_metrics,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8339f",
   "metadata": {},
   "source": [
    "# Custom corpus processor\n",
    "\n",
    "Takes the corpus and embedding model as input and returns a list of dictionaries that can be loaded into the corresponding Redis instance for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adfce2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_car_corpus(\n",
    "    corpus, emb_model\n",
    "):\n",
    "    corpus_data = []\n",
    "    corpus_texts = [c[\"text\"] for c in corpus]\n",
    "\n",
    "    text_embeddings = emb_model.embed_many(corpus_texts, as_buffer=True)\n",
    "\n",
    "    for i, c in enumerate(corpus):\n",
    "        corpus_data.append(\n",
    "            {\n",
    "                \"_id\": c[\"item_id\"],\n",
    "                \"text\": c[\"text\"],\n",
    "                \"make\": c[\"query_metadata\"][\"make\"],\n",
    "                \"model\": c[\"query_metadata\"][\"model\"],\n",
    "                \"vector\": text_embeddings[i],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return corpus_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e316b4",
   "metadata": {},
   "source": [
    "# Run the study\n",
    "\n",
    "At this moment, we can pass in our CUSTOM_SEARCH_METHOD_MAP and our custom corpus processor which can handle our car dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc56171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tyler.hutcherson/Library/Caches/pypoetry/virtualenvs/redis-retrieval-optimizer-Z5sMIYJj-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:56:39 datasets INFO   PyTorch version 2.7.0 available.\n",
      "09:56:40 sentence_transformers.SentenceTransformer INFO   Use pytorch device_name: mps\n",
      "09:56:40 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreating: loading corpus from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.60it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 36.69it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.04it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.18it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.12it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.56it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.25it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.53it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.27it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.48it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 36.56it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.55it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.90it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.01it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.20it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.45it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.65it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.36it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.15it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.05it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.01it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.60it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.79it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.81it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 32.98it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.21it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.96it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.50it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 36.06it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.57it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.98it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.42it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.87it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.03it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.14it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.35it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 36.25it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 32.23it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 36.36it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.40it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.12it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.41it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.67it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.36it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.65it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 32.82it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:56:43 sentence_transformers.SentenceTransformer INFO   Use pytorch device_name: mps\n",
      "09:56:43 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 55.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running search method: basic_vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.15it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.11it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.83it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.65it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 85.35it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.78it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 76.28it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 82.05it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 73.41it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 72.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running search method: pre_filter_vector\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from redis_retrieval_optimizer.grid_study import run_grid_study\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "CUSTOM_SEARCH_METHOD_MAP = {\n",
    "    \"basic_vector\": gather_vector_results,\n",
    "    \"pre_filter_vector\": gather_pre_filter_results,\n",
    "}\n",
    "\n",
    "# load environment variables containing necessary credentials\n",
    "load_dotenv()\n",
    "\n",
    "redis_url = os.environ.get(\"REDIS_URL\", \"redis://localhost:6379/0\")\n",
    "\n",
    "metrics = run_grid_study(\n",
    "    config_path=\"custom_grid_study_config.yaml\",\n",
    "    redis_url=redis_url,\n",
    "    corpus_processor=process_car_corpus,\n",
    "    search_method_map=CUSTOM_SEARCH_METHOD_MAP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47ef7edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_method</th>\n",
       "      <th>model</th>\n",
       "      <th>avg_query_time</th>\n",
       "      <th>recall@k</th>\n",
       "      <th>precision</th>\n",
       "      <th>ndcg@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pre_filter_vector</td>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.914903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic_vector</td>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.717676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       search_method                                   model  avg_query_time  \\\n",
       "1  pre_filter_vector  sentence-transformers/all-MiniLM-L6-v2        0.001590   \n",
       "0       basic_vector  sentence-transformers/all-MiniLM-L6-v2        0.002136   \n",
       "\n",
       "   recall@k  precision    ndcg@k  \n",
       "1       1.0       0.25  0.914903  \n",
       "0       0.9       0.23  0.717676  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[[\"search_method\", \"model\", \"avg_query_time\", \"recall@k\", \"precision\", \"ndcg@k\"]].sort_values(by=\"ndcg@k\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redis-retrieval-optimizer-Z5sMIYJj-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
