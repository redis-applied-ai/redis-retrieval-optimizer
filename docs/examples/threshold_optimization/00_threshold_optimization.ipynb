{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold Optimization\n",
    "\n",
    "After setting up `SemanticRouter` or `SemanticCache` it's best to tune the `distance_threshold` to get the most performance out of your system. `redisvl` works in tandem with the `redis-retrieval-optimizer` to provide some helper classes for easy, lightweight optimization.\n",
    "\n",
    "> **Note:** Threshold optimization with the optimizer library requires `python > 3.9.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install redis-retrieval-optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing a Semantic Cache\n",
    "\n",
    "Let's say you setup a Redis semantic cache with a `distance_threshold` of 0.5 and store the following entries:\n",
    "\n",
    "- prompt: `what is the capital of france?` response: `paris`\n",
    "- prompt: `what is the capital of morocco?` response: `rabat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00:16 datasets INFO   PyTorch version 2.3.0 available.\n",
      "15:00:16 sentence_transformers.SentenceTransformer INFO   Use pytorch device_name: mps\n",
      "15:00:16 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: redis/langcache-embed-v1\n"
     ]
    }
   ],
   "source": [
    "from redisvl.extensions.cache.llm import SemanticCache\n",
    "from redisvl.utils.vectorize import HFTextVectorizer\n",
    "\n",
    "sem_cache = SemanticCache(\n",
    "    name=\"sem_cache\",                                       # underlying search index name\n",
    "    redis_url=\"redis://localhost:6379\",                     # redis connection url string\n",
    "    distance_threshold=0.5,                                 # semantic cache distance threshold\n",
    "    vectorizer=HFTextVectorizer(\"redis/langcache-embed-v1\") # embedding model\n",
    ")\n",
    "\n",
    "paris_key = sem_cache.store(prompt=\"what is the capital of france?\", response=\"paris\")\n",
    "rabat_key = sem_cache.store(prompt=\"what is the capital of morocco?\", response=\"rabat\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works well but we want to make sure the cache only applies for the appropriate questions. If we test the cache with a question we don't want a response to we see that the current distance_threshold is too high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entry_id': 'c990cc06e5e77570e5f03360426d2b7f947cbb5a67daa8af8164bfe0b3e24fe3',\n",
       "  'prompt': 'what is the capital of france?',\n",
       "  'response': 'paris',\n",
       "  'vector_distance': 0.335606515408,\n",
       "  'inserted_at': 1756234823.0,\n",
       "  'updated_at': 1756234823.0,\n",
       "  'key': 'sem_cache:c990cc06e5e77570e5f03360426d2b7f947cbb5a67daa8af8164bfe0b3e24fe3'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem_cache.check(\"what's the capital of britain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Test Data and Optimize\n",
    "\n",
    "To optimize your semantic cache's distance threshold, use the `CacheThresholdOptimizer` class from the retrieval optimizer library. This tool helps you find the optimal threshold by evaluating test queries against your cache entries.\n",
    "\n",
    "Create a test dataset with the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance threshold before: 0.5 \n",
      "\n",
      "Distance threshold after: 0.10372881355932204 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from redis_retrieval_optimizer.threshold_optimization import CacheThresholdOptimizer\n",
    "\n",
    "test_data = [\n",
    "    {\n",
    "        \"query\": \"What's the capital of Britain?\",\n",
    "        \"query_match\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the capital of France??\",\n",
    "        \"query_match\": paris_key\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the capital city of Morocco?\",\n",
    "        \"query_match\": rabat_key\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"Distance threshold before: {sem_cache.distance_threshold} \\n\")\n",
    "\n",
    "optimizer = CacheThresholdOptimizer(sem_cache, test_data)\n",
    "optimizer.optimize()\n",
    "\n",
    "print(f\"Distance threshold after: {sem_cache.distance_threshold} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that we no longer match on the incorrect example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem_cache.check(\"what's the capital of britain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But still match on highly relevant prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entry_id': 'c990cc06e5e77570e5f03360426d2b7f947cbb5a67daa8af8164bfe0b3e24fe3',\n",
       "  'prompt': 'what is the capital of france?',\n",
       "  'response': 'paris',\n",
       "  'vector_distance': 0.0431388616562,\n",
       "  'inserted_at': 1756234823.0,\n",
       "  'updated_at': 1756234823.0,\n",
       "  'key': 'sem_cache:c990cc06e5e77570e5f03360426d2b7f947cbb5a67daa8af8164bfe0b3e24fe3'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem_cache.check(\"what's the capital city of france?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing a Semantic Router\n",
    "\n",
    "Very similar to the caching case, you can optimize your semantic router.\n",
    "\n",
    "### Define the routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.extensions.router import Route\n",
    "\n",
    "routes = [\n",
    "        Route(\n",
    "            name=\"greeting\",\n",
    "            references=[\"hello\", \"hi\"],\n",
    "            metadata={\"type\": \"greeting\"},\n",
    "            distance_threshold=0.5,\n",
    "        ),\n",
    "        Route(\n",
    "            name=\"farewell\",\n",
    "            references=[\"bye\", \"goodbye\"],\n",
    "            metadata={\"type\": \"farewell\"},\n",
    "            distance_threshold=0.5,\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the SemanticRouter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00:27 sentence_transformers.SentenceTransformer INFO   Use pytorch device_name: mps\n",
      "15:00:27 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from redisvl.extensions.router import SemanticRouter\n",
    "from redisvl.utils.vectorize import HFTextVectorizer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Initialize the SemanticRouter\n",
    "router = SemanticRouter(\n",
    "    name=\"greeting-router\",\n",
    "    vectorizer=HFTextVectorizer(),\n",
    "    routes=routes,\n",
    "    redis_url=\"redis://localhost:6379\",\n",
    "    overwrite=True # Blow away any other routing index with this name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    # Greetings\n",
    "    {\"query\": \"hello\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"hi\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"hey\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"greetings\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"good morning\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"good afternoon\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"good evening\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"howdy\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"what's up\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"yo\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"hiya\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"salutations\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"how's it going\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"how are you\", \"query_match\": \"greeting\"},\n",
    "    {\"query\": \"nice to meet you\", \"query_match\": \"greeting\"},\n",
    "    # Farewells\n",
    "    {\"query\": \"goodbye\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"bye\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"see you later\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"take care\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"farewell\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"have a good day\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"see you soon\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"catch you later\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"so long\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"peace out\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"later\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"all the best\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"take it easy\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"have a good one\", \"query_match\": \"farewell\"},\n",
    "    {\"query\": \"cheerio\", \"query_match\": \"farewell\"},\n",
    "    # Null matches\n",
    "    {\"query\": \"what's the capital of britain?\", \"query_match\": \"\"},\n",
    "    {\"query\": \"what does laffy taffy taste like?\", \"query_match\": \"\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize\n",
    "\n",
    ">Note: by default route distance threshold optimization will use a random search to find the best threshold since, unlike caching, there are many thresholds to optimize concurrently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route thresholds before: {'greeting': 0.5, 'farewell': 0.5} \n",
      "\n",
      "Eval metric F1: start 0.438, end 0.656 \n",
      "Ending thresholds: {'greeting': 0.15102363464037255, 'farewell': 0.7303030303030302}\n"
     ]
    }
   ],
   "source": [
    "from redis_retrieval_optimizer.threshold_optimization import RouterThresholdOptimizer\n",
    "\n",
    "print(f\"Route thresholds before: {router.route_thresholds} \\n\")\n",
    "\n",
    "optimizer = RouterThresholdOptimizer(router, test_data)\n",
    "optimizer.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteMatch(name='greeting', distance=0.295984059572)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the router with a statement\n",
    "route_match = router(\"hi there\")\n",
    "route_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "router.delete()\n",
    "sem_cache.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
