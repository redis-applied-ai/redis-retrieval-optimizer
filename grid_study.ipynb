{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b64475",
   "metadata": {},
   "source": [
    "# Grid study\n",
    "\n",
    "We will define a study config to test the relative retrieval scores returned from bm25 search vs. vector as an example.\n",
    "\n",
    "## Data Requirements\n",
    "\n",
    "The hardest part of any evaluation is collect and formatting a good dataset. To run a study with the retrieval optimizer you will need the following sets of data.\n",
    "\n",
    "### Corpus\n",
    "\n",
    "This is the data that we will make up the overall set of objects we are searching against and is what will be indexed in Redis.\n",
    "\n",
    "General form:\n",
    "```json\n",
    "{\n",
    "    \"corpus_id\": {\n",
    "        \"text\": \"test to be searched on or vectorized\",\n",
    "        \"title\": \"associated title\",\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Concrete example:\n",
    "```json\n",
    "{\n",
    "    \"MED-10\": {\n",
    "        \"text\": \"Recent studies have suggested that statins, an established drug group in the prevention of cardiovascular mortality, could delay or prevent breast cancer recurrence but the effect on disease-specific mortality remains unclear. ...\",\n",
    "        \"title\": \"Statin Use and Breast Cancer Survival: A Nationwide Cohort Study from Finland\"\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### Queries\n",
    "\n",
    "The queries that will be executed against the corpus to measure performance.\n",
    "\n",
    "General form:\n",
    "```json\n",
    "{\n",
    "    \"query_id\": \"query text\",\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "Concrete example:\n",
    "```json\n",
    "{\n",
    "    \"PLAIN-2\": \"Do Cholesterol Statin Drugs Cause Breast Cancer?\",\n",
    "    \"PLAIN-12\": \"Exploiting Autophagy to Live Longer\",\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### Qrels\n",
    "\n",
    "The labeled set of scores used for evaluation of the queries against the corpus.\n",
    "\n",
    "General form:\n",
    "```json\n",
    "{\n",
    "    \"query_id\": {\n",
    "        \"corpus_id\": \"score\",\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "Concrete example:\n",
    "```json\n",
    "{\n",
    "    \"PLAIN-2\": {\n",
    "        \"MED-2427\": 2,\n",
    "        \"MED-2440\": 1,\n",
    "        \"MED-2434\": 1,\n",
    "        \"MED-2435\": 1,\n",
    "        \"MED-2436\": 1,\n",
    "    },\n",
    "    \"PLAIN-12\": {\n",
    "        \"MED-2513\": 2,\n",
    "        \"MED-5237\": 2,\n",
    "    },\n",
    "}\n",
    "```\n",
    "\n",
    "Note: for precision, recall, f1 simple existence of the key (1 or 0) is what drives the metric. For NCDG and ranking is when scores other than 1 become relevant since those account for ranking.\n",
    "\n",
    "\n",
    "## Sourcing data\n",
    "\n",
    "For this example, we are making use of the awesome datasets available through [beir benchmarking IR project](https://github.com/beir-cellar/beir). For these datasets, there is a helper within the retrieval benchmark to test any of your specific methods with these datasets. However, for the most use-case-specific optimization you can create your own dataset it simply needs to be of this general structure. Additionally, if you have a few examples of your data it can be very helpful to use an LLM to extend and create more examples for your testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66894d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:43:35 beir.datasets.data_loader INFO   Loading Corpus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c656e1cbaa4027b4de05e38202d5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:43:35 beir.datasets.data_loader INFO   Loaded 3633 TEST Documents.\n",
      "09:43:35 beir.datasets.data_loader INFO   Doc Example: {'text': 'Recent studies have suggested that statins, an established drug group in the prevention of cardiovascular mortality, could delay or prevent breast cancer recurrence but the effect on disease-specific mortality remains unclear. We evaluated risk of breast cancer death among statin users in a population-based cohort of breast cancer patients. The study cohort included all newly diagnosed breast cancer patients in Finland during 1995–2003 (31,236 cases), identified from the Finnish Cancer Registry. Information on statin use before and after the diagnosis was obtained from a national prescription database. We used the Cox proportional hazards regression method to estimate mortality among statin users with statin use as time-dependent variable. A total of 4,151 participants had used statins. During the median follow-up of 3.25 years after the diagnosis (range 0.08–9.0 years) 6,011 participants died, of which 3,619 (60.2%) was due to breast cancer. After adjustment for age, tumor characteristics, and treatment selection, both post-diagnostic and pre-diagnostic statin use were associated with lowered risk of breast cancer death (HR 0.46, 95% CI 0.38–0.55 and HR 0.54, 95% CI 0.44–0.67, respectively). The risk decrease by post-diagnostic statin use was likely affected by healthy adherer bias; that is, the greater likelihood of dying cancer patients to discontinue statin use as the association was not clearly dose-dependent and observed already at low-dose/short-term use. The dose- and time-dependence of the survival benefit among pre-diagnostic statin users suggests a possible causal effect that should be evaluated further in a clinical trial testing statins’ effect on survival in breast cancer patients.', 'title': 'Statin Use and Breast Cancer Survival: A Nationwide Cohort Study from Finland'}\n",
      "09:43:35 beir.datasets.data_loader INFO   Loading Queries...\n",
      "09:43:35 beir.datasets.data_loader INFO   Loaded 323 TEST Queries.\n",
      "09:43:35 beir.datasets.data_loader INFO   Query Example: Do Cholesterol Statin Drugs Cause Breast Cancer?\n"
     ]
    }
   ],
   "source": [
    "from redis_retrieval_optimizer.corpus_processors import eval_beir\n",
    "\n",
    "# check the link above for different datasets to try\n",
    "beir_dataset_name = \"nfcorpus\"\n",
    "\n",
    "# Load sample data\n",
    "corpus, queries, qrels = eval_beir.get_beir_dataset(beir_dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b707b3",
   "metadata": {},
   "source": [
    "Now that we have our data we will save it locally to the gitignored `data/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05a3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"data/{beir_dataset_name}_corpus.json\", \"w\") as f:\n",
    "    json.dump(corpus, f)\n",
    "\n",
    "with open(f\"data/{beir_dataset_name}_queries.json\", \"w\") as f:\n",
    "    json.dump(queries, f)\n",
    "\n",
    "with open(f\"data/{beir_dataset_name}_qrels.json\", \"w\") as f:\n",
    "    json.dump(qrels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ce092",
   "metadata": {},
   "source": [
    "# Define a study config\n",
    "\n",
    "To set the parameters of our study we need to define a study configuration file.\n",
    "\n",
    "Example:\n",
    "```yaml\n",
    "# paths to necessary data files\n",
    "corpus: \"data/nfcorpus_corpus.json\" # optional if from_existing\n",
    "queries: \"data/nfcorpus_queries.json\"\n",
    "qrels: \"data/nfcorpus_qrels.json\"\n",
    "\n",
    "# vector field names\n",
    "vector_field_name: \"vector\" # name of the vector field to search on\n",
    "text_field_name: \"text\" # name of the text field for lexical search\n",
    "index_settings:\n",
    "  name: \"optimize\"\n",
    "  from_existing: false # true if sourcing corpus from existing redis instance\n",
    "\n",
    "# will run all search methods for each embedding model and then iterate\n",
    "embedding_models: # embedding cache would be awesome here.\n",
    "# if from_existing is true, first record is assumed to be the one used to create the index\n",
    "  - type: \"hf\"\n",
    "    model: \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    dim: 384\n",
    "    embedding_cache_name: \"vec-cache\" # avoid names with including 'ret-opt' as this can cause collisions\n",
    "\n",
    "search_methods: [\"bm25\", \"vector\"] # the search methods to run against the dataset\n",
    "```\n",
    "\n",
    "## Available search methods\n",
    "\n",
    "The available search methods are defined in `redis_retrieval_optimizer.search_methods.__init__` and you can see the active `SEARCH_METHOD_MAP` which maps the string input in search_method to the corresponding function.\n",
    "\n",
    "You can define your own SEARCH_METHOD_MAP and pass it in to define your custom retrieval logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6dade2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:28:20 sentence_transformers.cross_encoder.CrossEncoder INFO   Use pytorch device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bm25': <function redis_retrieval_optimizer.search_methods.bm25.gather_bm25_results(queries, index, emb_model)>,\n",
       " 'rerank': <function redis_retrieval_optimizer.search_methods.rerank.gather_rerank_results(queries, index, emb_model)>,\n",
       " 'lin_combo': <function redis_retrieval_optimizer.search_methods.lin_combo.gather_lin_combo_results(queries, index, emb_model, alpha=0.7)>,\n",
       " 'vector': <function redis_retrieval_optimizer.search_methods.vector.gather_vector_results(queries, index, emb_model)>,\n",
       " 'weighted_rrf': <function redis_retrieval_optimizer.search_methods.weighted_rrf.gather_weighted_rrf(queries, index, emb_model)>}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from redis_retrieval_optimizer.search_methods import SEARCH_METHOD_MAP\n",
    "\n",
    "SEARCH_METHOD_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e316b4",
   "metadata": {},
   "source": [
    "# Run a study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc56171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:01:43 sentence_transformers.cross_encoder.CrossEncoder INFO   Use pytorch device: mps\n",
      "11:01:43 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:01:44 sentence_transformers.SentenceTransformer INFO   Use pytorch device_name: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4eb9e3be23a42fda6c22ea79348ac70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:01:45 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "11:01:46 sentence_transformers.SentenceTransformer INFO   Use pytorch device_name: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/.pyenv/versions/3.11.9/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12178e76499c4082bcba9c9e08c9658b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreating: loading corpus from file\n",
      "11:01:48 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "11:01:49 sentence_transformers.SentenceTransformer INFO   Use pytorch device_name: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff26488cab04dd09a636203659f525e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running search method: bm25\n",
      "Running search method: vector\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from redis_retrieval_optimizer.grid_study import run_grid_study\n",
    "from redis_retrieval_optimizer.corpus_processors import eval_beir\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment variables containing necessary credentials\n",
    "load_dotenv()\n",
    "\n",
    "redis_url = os.environ.get(\"REDIS_URL\", \"redis://localhost:6379/0\")\n",
    "\n",
    "metrics = run_grid_study(\n",
    "    config_path=\"grid_study_config.yaml\",\n",
    "    redis_url=\"redis://localhost:6379/0\",\n",
    "    corpus_processor=eval_beir.process_corpus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ef7edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search_method': ['bm25', 'vector'],\n",
       " 'ret_k': [6, 6],\n",
       " 'algorithm': ['flat', 'flat'],\n",
       " 'ef_construction': [0, 0],\n",
       " 'ef_runtime': [0, 0],\n",
       " 'm': [0, 0],\n",
       " 'distance_metric': ['cosine', 'cosine'],\n",
       " 'vector_data_type': ['float32', 'float32'],\n",
       " 'model': ['sentence-transformers/all-MiniLM-L6-v2',\n",
       "  'sentence-transformers/all-MiniLM-L6-v2'],\n",
       " 'model_dim': [384, 384],\n",
       " 'recall@k': [0.11579800796961262, 0.11965315421231895],\n",
       " 'ndcg@k': [0.16890919365750603, 0.1655733514156841],\n",
       " 'f1@k': [0.12598202968456776, 0.12115336056131429],\n",
       " 'total_indexing_time': [0, 0],\n",
       " 'precision': [0.32389060887512905, 0.30299277605779157]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834e6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
